{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448f2ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f86a2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation,Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1f8c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ebee94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of observations \n",
    "no_observations=env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c48fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# umber of actions can take and those are continous / discrete  identifed\n",
    "no_actions= env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ecd744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7f5013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When creating neural network number of observations == input neurons number and number of neurons on final layer == actions\n",
    "\n",
    "# Traiing Model network - Value Network\n",
    "\n",
    "model = Sequential()\n",
    "#Add layers\n",
    "model.add(Dense(4, input_shape=(1,no_observations)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#  Input shape must be provided defined in first layer to compile properly but can define at any layer\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "\n",
    "# output or last layer gives number of actions\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9169b6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076cdcfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import clone_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36acfaa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model copying \n",
    "target_model = clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1573a004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Network ouline defined - But before training Configure Hyperparametrs such as\n",
    "\n",
    "learning_parameter = 0.001\n",
    "Epochs = 500  # number of iterations \n",
    "epsilon = 1.0 # How fast will learn 1 -> max but later modify according to learning with accracy\n",
    "epsilon_reduce = 0.995 # 99.5% reduced to previous epsilon\n",
    "gamma = 0.95\n",
    "\n",
    "# Epsilon - greedy => Exploration vs Exploitaction to select / predict a action value\n",
    "# So required are a model, observation and epsilon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "070909d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greedy_epsilon_action(model,observation,epsilon):\n",
    "    \n",
    "    # Intialy not aware which action to perform so make a random action and then learn\n",
    "    if np.random.random() > epsilon:\n",
    "        predictions = model.predict(observation,verbose =0)\n",
    "        action = np.argmax(predictions)  # picking max value to perform aaction\n",
    "        \n",
    "    else:\n",
    "        #Explore\n",
    "        action = np.random.randint(0, env.action_space.n) # choosing randomly an action b/w 0 to max actions can perform on env\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "420ace3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from collections import deque\n",
    "\n",
    "# deque(maxlen=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dd1d475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# d= deque(maxlen=5)\n",
    "\n",
    "# for i in range(10):\n",
    "#     d.append(i)\n",
    "#     print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bccf298c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import deque\n",
    "\n",
    "# for replay buffer - Need - window / repay buffer [Deque obj] size to store , batch size, model, target model\n",
    "\n",
    "replay_buffer = deque(maxlen=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62cf9a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replay - Pick buffer size / sequence of frames/data to hold \n",
    "# use deque from collections \n",
    "import random\n",
    "\n",
    "\n",
    "def replay(buffer,batch_size,model,target_model):\n",
    "    \n",
    "    if len(buffer) < batch_size:\n",
    "        return # No action untill buffer filled\n",
    "    samples = random.sample(buffer,batch_size)   # select ramdomly batch of values from buffer\n",
    "    \n",
    "    target_batch = []\n",
    "    \n",
    "    # samples -> collection of buffers ,1 buffer = 1 observations, observation -> state,reward,action, new_state,done_flag\n",
    "    zipped_samples = list(zip(*samples))      #tuple of \n",
    "    states, actions ,rewards,new_states,dones = zipped_samples\n",
    "    \n",
    "    targets = target_model.predict(np.array(states),verbose =0)\n",
    "    \n",
    "    q_values = model.predict(np.array(new_states),verbose=0).flatten()\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        q_value = q_values[i]\n",
    "        target = targets[i].copy()\n",
    "        \n",
    "        if dones[i] :\n",
    "            target[0][actions[i]] = rewards[i]\n",
    "            \n",
    "        else:\n",
    "            target[0][actions[i]] = rewards[i] + q_value*gamma\n",
    "            \n",
    "        target_batch.append(target)\n",
    "        \n",
    "    model.fit(np.array(states),np.array(target_batch),epochs =1, verbose= 0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab34abf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_target_model = 10\n",
    "\n",
    "def update_model_handler(ephocs, update_target_model, model,target_model):\n",
    "    if ephocs >0 and ephocs % update_target_model == 0:\n",
    "        target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90bd8cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer=Adam(learning_rate=learning_parameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7709149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41ec7a87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 15 at ephoc:0 when epsilon: 0.9000874278732445\n",
      "score: 34 at ephoc:10 when epsilon: 0.8560822709551227\n",
      "score: 42 at ephoc:20 when epsilon: 0.8142285204175609\n",
      "score: 42 at ephoc:30 when epsilon: 0.7744209942832988\n",
      "score: 48 at ephoc:40 when epsilon: 0.736559652908221\n",
      "score: 48 at ephoc:50 when epsilon: 0.7005493475733617\n",
      "score: 48 at ephoc:60 when epsilon: 0.6662995813682115\n",
      "score: 48 at ephoc:70 when epsilon: 0.6337242817644086\n",
      "score: 48 at ephoc:80 when epsilon: 0.6027415843082742\n",
      "score: 48 at ephoc:90 when epsilon: 0.5732736268885887\n",
      "score: 48 at ephoc:100 when epsilon: 0.5452463540625918\n",
      "score: 48 at ephoc:110 when epsilon: 0.5185893309484582\n",
      "score: 68 at ephoc:120 when epsilon: 0.4932355662165453\n",
      "score: 68 at ephoc:130 when epsilon: 0.46912134373457726\n",
      "score: 68 at ephoc:140 when epsilon: 0.446186062443672\n",
      "score: 68 at ephoc:150 when epsilon: 0.42437208406280985\n",
      "score: 68 at ephoc:160 when epsilon: 0.4036245882390106\n",
      "score: 68 at ephoc:170 when epsilon: 0.38389143477919885\n",
      "score: 68 at ephoc:180 when epsilon: 0.36512303261753626\n",
      "score: 68 at ephoc:190 when epsilon: 0.3472722151889232\n",
      "score: 68 at ephoc:200 when epsilon: 0.3302941218954743\n",
      "score: 68 at ephoc:210 when epsilon: 0.3141460853680822\n",
      "score: 68 at ephoc:220 when epsilon: 0.2987875242397482\n",
      "score: 68 at ephoc:230 when epsilon: 0.28417984116121187\n",
      "score: 68 at ephoc:240 when epsilon: 0.2702863258025825\n",
      "score: 68 at ephoc:250 when epsilon: 0.2570720625972084\n",
      "score: 68 at ephoc:260 when epsilon: 0.24450384299593592\n",
      "score: 68 at ephoc:270 when epsilon: 0.23255008201124722\n",
      "score: 68 at ephoc:280 when epsilon: 0.2211807388415433\n",
      "score: 68 at ephoc:290 when epsilon: 0.21036724137609603\n",
      "score: 68 at ephoc:300 when epsilon: 0.2000824143909432\n",
      "score: 68 at ephoc:310 when epsilon: 0.1903004112552766\n",
      "score: 68 at ephoc:320 when epsilon: 0.18099664897669618\n",
      "score: 68 at ephoc:330 when epsilon: 0.17214774642209296\n",
      "score: 68 at ephoc:340 when epsilon: 0.16373146555890544\n",
      "score: 68 at ephoc:350 when epsilon: 0.1557266555690826\n",
      "score: 68 at ephoc:360 when epsilon: 0.14811319969530845\n",
      "score: 68 at ephoc:370 when epsilon: 0.14087196468590776\n",
      "score: 68 at ephoc:380 when epsilon: 0.13398475271138335\n",
      "score: 68 at ephoc:390 when epsilon: 0.12743425563174798\n",
      "score: 68 at ephoc:400 when epsilon: 0.12120401149972035\n",
      "score: 68 at ephoc:410 when epsilon: 0.11527836319047392\n",
      "score: 68 at ephoc:420 when epsilon: 0.10964241905397228\n",
      "score: 68 at ephoc:430 when epsilon: 0.1042820154910064\n",
      "score: 68 at ephoc:440 when epsilon: 0.09918368135888474\n",
      "score: 68 at ephoc:450 when epsilon: 0.0943346041173244\n",
      "score: 68 at ephoc:460 when epsilon: 0.08972259762946533\n",
      "score: 68 at ephoc:470 when epsilon: 0.08533607153708872\n",
      "score: 68 at ephoc:480 when epsilon: 0.0811640021330769\n",
      "score: 68 at ephoc:490 when epsilon: 0.07719590465791494\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "\n",
    "for ephocs in range(Epochs):\n",
    "    observation = env.reset()[0]\n",
    "    observation = observation.reshape([1,4])\n",
    "    done = False\n",
    "    \n",
    "    point = 0 \n",
    "    while not done:\n",
    "        \n",
    "        point += 1\n",
    "        action = greedy_epsilon_action(model,observation,epsilon)\n",
    "        next_observation,reward,done,truncate,info = env.step(action)\n",
    "        next_observation = next_observation.reshape([1,4])\n",
    "        \n",
    "        replay_buffer.append((observation,action,reward,next_observation,done))\n",
    "        observation = next_observation\n",
    "        \n",
    "        replay(replay_buffer,32,model,target_model)\n",
    "    \n",
    "    epsilon *= epsilon_reduce\n",
    "    \n",
    "    update_model_handler(ephocs, update_target_model, model,target_model)\n",
    "    \n",
    "    if point > score:\n",
    "        score = point\n",
    "        \n",
    "    if ephocs % 10 == 0:\n",
    "        print(f'score: {score} at ephoc:{ephocs} when epsilon: {epsilon}')\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a7ef2c8-002b-42b3-8956-a6985edc771f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01554028,  0.02787708,  0.02047598, -0.0440359 ], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = env.reset()[0]\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92dcb7ff-b4dd-4536-a57f-5bb925991e70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[[-0.18335414 -1.7350829   0.22137108  2.7829535 ]] 1.0 True False {}\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()[0]\n",
    "        #For debbuging we use render\n",
    "for i in range(3000):\n",
    "    env.render()\n",
    "    action = np.argmax(model.predict(observation.reshape([1,4]),verbose=0))\n",
    "    observation,reward,done,trancate,info = env.step(action)\n",
    "    observation = observation.reshape([1,4])\n",
    "            \n",
    "    if done:\n",
    "        print(i)\n",
    "        print(observation,reward,done,trancate,info)\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0bed45c-5112-4744-8503-6d24f79f5666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248bc7e2-42ea-48dd-bdac-c00fa1f9793d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
